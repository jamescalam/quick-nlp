{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Dhivehi Pairs\n",
    "\n",
    "Here we will try to distil sentence transformer performance from a *paraphrase* sentence transformer to a pretrained XLMR model that has *not* been pretrained with Dhivehi text.\n",
    "\n",
    "First task is to load the Dhivehi pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"formed bank to increase competitiveness, reduce interest\"\\tބޭންކު ހެދީ ވާދަވެރިކަން ބޮޑުކޮށް، އިންޓަރެސްޓް ކުޑަ ކުރަން\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/entodv.tsv', 'r') as fp:\n",
    "    entodv = fp.readlines()\n",
    "\n",
    "entodv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the shareholders of commercial bank of maldives (cbm), champa hussain afeef has stated he started a new bank to increase competitiveness and reduce interest rates in the market. \\tރާއްޖޭގައި އިތުރު ބޭންކެއް ހެދުމުގެ މަގުސަދަކީ ބޭންކިން ދާއިރާގެ ވާދަވެރިކަން ބޮޑުކޮށް، އިންޓަރެސްޓް ރޭޓް ކުޑަ ކުރުމަށް ބާރު އަޅަން ކަމަށް ކޮމާޝަލް ބޭންކް އޮފް މޯލްޑިވްސް (ސީބީއެމް)ގެ އެއް ހިއްސާދާރު އަދި މަޝްހޫރު ވިޔަފާރިވެރިޔާ، ޗަމްޕާ ހުސެއިން އަފީފު މިއަދު ވިދާޅުވެއްޖެ އެވެ.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entodv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in an exclusive interview to avas, champa resorts chairman afeef said that forming a bank was a vision of his brother popular businessman mohamed moosa (uhchu). afeef said that when he first entered the resort market, interest rates were extremely high and therefore negatively impacted on business growth. therefore, he said he had envisioned opening a bank to make the sector more competitive and give easier access to loans and other financial instruments. \\tއަވަސް އަށް ދެއްވި ހާއްސަނ އިންޓަވިއެއްގައި ކްރައުން އެންޑް ޗަމްޕާ ރިސޯޓްސްގެ ޗެއާމަން އަފީފު ވިދާޅުވީ ބޭންކެއް ހެދުމުގެ ވިސްނުމަކީ އަފީފްގެ ބޭބެ، މަޝްހޫރު ވިޔަފާރިވެރިޔާ، މުހައްމަދު މޫސާ (އުއްޗު) ގެ ވިސްނުމެއް ކަމަށެވެ. އަފީފް ވިދާޅުވީ އެންމެ ފުރަތަމަ ރިސޯޓް ހަދަން މަސައްކަތް ކުރެއްވި އިރު އޭރު ރާއްޖޭގައި އިންޓަރެސްޓް ރޭޓް އުޅެނީ ވަރަށް ބޮޑު ކަމަށާއި އެކަމުގެ ސަބަބުން ވިޔަފާރި ފުޅާ ކުރަން ލޯނު ނެގުން އޮތީ ދަތިކަމަކަށް ވެފައި ކަމަށެވެ. އަދި ބޭންކެއް ހެދުމުގެ ހުވަފެން އައީ، މި ދާއިރާއަށް ވާދަވެރިކަން ގެނެސްގެން ލޯނު ފަދަ ފައިނޭންސް ލިބޭނެ އިންތިޒާމް ހަމަޖެއްސުމުގެ ވިސްނުމުގައި ކަމަށެވެ.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entodv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good so far, let's split some of this data to act as our evaluation set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: 23770\n",
      "train set: 22582\n",
      "dev set: 1188\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "dev_split = int(len(entodv) * 0.05)\n",
    "\n",
    "idx = sample(list(range(len(entodv))), dev_split)\n",
    "\n",
    "dev_set = [entodv[i] for i in idx]\n",
    "train_set = [entodv[i] for i in range(len(entodv)) if i not in idx]\n",
    "\n",
    "print(f\"original: {len(entodv)}\\ntrain set: {len(train_set)}\\ndev set: {len(dev_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go ahead and save these as a .tsv.gz files ready for loading into our `ParallelSentencesDataset` object later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entodv-dev.tsv.gz', 'entodv-train.tsv.gz', 'entodv.tsv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "with gzip.open('../data/entodv-train.tsv.gz', 'wt', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(train_set))\n",
    "with gzip.open('../data/entodv-dev.tsv.gz', 'wt', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(dev_set))\n",
    "\n",
    "os.listdir('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to confirm that the XLMR tokenizer can deal with Dhivehi characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ބޭންކު ހެދީ ވާދަވެރިކަން ބޮޑުކޮށް، އިންޓަރެސްޓް ކުޑަ ކުރަން\\n',\n",
       " 'ރާއްޖޭގައި އިތުރު ބޭންކެއް ހެދުމުގެ މަގުސަދަކީ ބޭންކިން ދާއިރާގެ ވާދަވެރިކަން ބޮޑުކޮށް، އިންޓަރެސްޓް ރޭޓް ކުޑަ ކުރުމަށް ބާރު އަޅަން ކަމަށް ކޮމާޝަލް ބޭންކް އޮފް މޯލްޑިވްސް (ސީބީއެމް)ގެ އެއް ހިއްސާދާރު އަދި މަޝްހޫރު ވިޔަފާރިވެރިޔާ، ޗަމްޕާ ހުސެއިން އަފީފު މިއަދު ވިދާޅުވެއްޖެ އެވެ.\\n',\n",
       " 'އަވަސް އަށް ދެއްވި ހާއްސަނ އިންޓަވިއެއްގައި ކްރައުން އެންޑް ޗަމްޕާ ރިސޯޓްސްގެ ޗެއާމަން އަފީފު ވިދާޅުވީ ބޭންކެއް ހެދުމުގެ ވިސްނުމަކީ އަފީފްގެ ބޭބެ، މަޝްހޫރު ވިޔަފާރިވެރިޔާ، މުހައްމަދު މޫސާ (އުއްޗު) ގެ ވިސްނުމެއް ކަމަށެވެ. އަފީފް ވިދާޅުވީ އެންމެ ފުރަތަމަ ރިސޯޓް ހަދަން މަސައްކަތް ކުރެއްވި އިރު އޭރު ރާއްޖޭގައި އިންޓަރެސްޓް ރޭޓް އުޅެނީ ވަރަށް ބޮޑު ކަމަށާއި އެކަމުގެ ސަބަބުން ވިޔަފާރި ފުޅާ ކުރަން ލޯނު ނެގުން އޮތީ ދަތިކަމަކަށް ވެފައި ކަމަށެވެ. އަދި ބޭންކެއް ހެދުމުގެ ހުވަފެން އައީ، މި ދާއިރާއަށް ވާދަވެރިކަން ގެނެސްގެން ލޯނު ފަދަ ފައިނޭންސް ލިބޭނެ އިންތިޒާމް ހަމަޖެއްސުމުގެ ވިސްނުމުގައި ކަމަށެވެ.\\n',\n",
       " 'ބޭބެ، މުހައްމަދު މޫސާ، އުއްޗު ބޭންކް އޮފް މޯލްޑިވްސް ހެދުމުގެ މާކުރީގައި ގެންގުޅުނު ހިޔާލެއް މިއީ. އަޅުގަނޑުމެން އެންމެ ފުރަތަމަ [ޓޫރިޒަމް] ވިޔަފާރިއަށް އައިރު ބޭންކުގެ އިންޓްރެސްޓް ރޭޓް އުޅެނީ 21-22 ޕަސެންޓުގައި. އެހެންވެ މި ހިޔާލުއައީ. މި އަށް ކޮމްޕެޓިޝަނެއް ދީގެން ނޫނީ އަޅުގަނޑަށް އެނގޭ އިންޓްރެސްޓް ރޭޓް ކުޑަ ނުވާނެކަން، އަފީފު ވިދާޅުވި އެވެ.\\n',\n",
       " 'ސީބީއެމް ހަދާފައިވަނީ ދުނިޔޭގެ އެކި ހިސާބުތަކުގައި 200 އެއްހާ ބްރާންޗު ހިންގާ، ސްރީ ލަންކާގެ ކޮމާޝަލް ބޭންކްގެ 55 ޕަސެންޓް ހިއްސާ އާއި ސީބީއެމްގައި ޓްރީ ޓޮޕްގެ 45 ޕަސެންޓް ހިއްސާ އޮންނަ ގޮތަށެވެ. މި ބޭންކް ހުޅުވާފައިވަނީ ގާތްގަނޑަކަށް 150 މިލިއަން ރުފިޔާގެ ރައުސުލްމާލަކުންނެވެ.\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for pair in entodv[:5]:\n",
    "    dv = pair.split('\\t')[1]\n",
    "    sentences.append(dv)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'ބޭންކު', '▁', 'ހެދީ', '▁', 'ވާދަވެރިކަން', '▁', 'ބޮޑުކޮށް', '،', '▁', 'އިންޓަރެސްޓް', '▁', 'ކުޑަ', '▁', 'ކުރަން']\n",
      "['▁', 'ރާއްޖޭގައި', '▁', 'އިތުރު', '▁', 'ބޭންކެއް', '▁', 'ހެދުމުގެ', '▁', 'މަގުސަދަކީ', '▁', 'ބޭންކިން', '▁', 'ދާއިރާގެ', '▁', 'ވާދަވެރިކަން', '▁', 'ބޮޑުކޮށް', '،', '▁', 'އިންޓަރެސްޓް', '▁', 'ރޭޓް', '▁', 'ކުޑަ', '▁', 'ކުރުމަށް', '▁', 'ބާރު', '▁', 'އަޅަން', '▁', 'ކަމަށް', '▁', 'ކޮމާޝަލް', '▁', 'ބޭންކް', '▁', 'އޮފް', '▁', 'މޯލްޑިވްސް', '▁(', 'ސީބީއެމް', ')', 'ގެ', '▁', 'އެއް', '▁', 'ހިއްސާދާރު', '▁', 'އަދި', '▁', 'މަޝްހޫރު', '▁', 'ވިޔަފާރިވެރިޔާ', '،', '▁', 'ޗަމްޕާ', '▁', 'ހުސެއިން', '▁', 'އަފީފު', '▁', 'މިއަދު', '▁', 'ވިދާޅުވެއްޖެ', '▁', 'އެވެ', '.']\n",
      "['▁', 'އަވަސް', '▁', 'އަށް', '▁', 'ދެއްވި', '▁', 'ހާއްސަނ', '▁', 'އިންޓަވިއެއްގައި', '▁', 'ކްރައުން', '▁', 'އެންޑް', '▁', 'ޗަމްޕާ', '▁', 'ރިސޯޓްސްގެ', '▁', 'ޗެއާމަން', '▁', 'އަފީފު', '▁', 'ވިދާޅުވީ', '▁', 'ބޭންކެއް', '▁', 'ހެދުމުގެ', '▁', 'ވިސްނުމަކީ', '▁', 'އަފީފްގެ', '▁', 'ބޭބެ', '،', '▁', 'މަޝްހޫރު', '▁', 'ވިޔަފާރިވެރިޔާ', '،', '▁', 'މުހައްމަދު', '▁', 'މޫސާ', '▁(', 'އުއްޗު', ')', '▁', 'ގެ', '▁', 'ވިސްނުމެއް', '▁', 'ކަމަށެވެ', '.', '▁', 'އަފީފް', '▁', 'ވިދާޅުވީ', '▁', 'އެންމެ', '▁', 'ފުރަތަމަ', '▁', 'ރިސޯޓް', '▁', 'ހަދަން', '▁', 'މަސައްކަތް', '▁', 'ކުރެއްވި', '▁', 'އިރު', '▁', 'އޭރު', '▁', 'ރާއްޖޭގައި', '▁', 'އިންޓަރެސްޓް', '▁', 'ރޭޓް', '▁', 'އުޅެނީ', '▁', 'ވަރަށް', '▁', 'ބޮޑު', '▁', 'ކަމަށާއި', '▁', 'އެކަމުގެ', '▁', 'ސަބަބުން', '▁', 'ވިޔަފާރި', '▁', 'ފުޅާ', '▁', 'ކުރަން', '▁', 'ލޯނު', '▁', 'ނެގުން', '▁', 'އޮތީ', '▁', 'ދަތިކަމަކަށް', '▁', 'ވެފައި', '▁', 'ކަމަށެވެ', '.', '▁', 'އަދި', '▁', 'ބޭންކެއް', '▁', 'ހެދުމުގެ', '▁', 'ހުވަފެން', '▁', 'އައީ', '،', '▁', 'މި', '▁', 'ދާއިރާއަށް', '▁', 'ވާދަވެރިކަން', '▁', 'ގެނެސްގެން', '▁', 'ލޯނު', '▁', 'ފަދަ', '▁', 'ފައިނޭންސް', '▁', 'ލިބޭނެ', '▁', 'އިންތިޒާމް', '▁', 'ހަމަޖެއްސުމުގެ', '▁', 'ވިސްނުމުގައި', '▁', 'ކަމަށެވެ', '.']\n",
      "['▁', 'ބޭބެ', '،', '▁', 'މުހައްމަދު', '▁', 'މޫސާ', '،', '▁', 'އުއްޗު', '▁', 'ބޭންކް', '▁', 'އޮފް', '▁', 'މޯލްޑިވްސް', '▁', 'ހެދުމުގެ', '▁', 'މާކުރީގައި', '▁', 'ގެންގުޅުނު', '▁', 'ހިޔާލެއް', '▁', 'މިއީ', '.', '▁', 'އަޅުގަނޑުމެން', '▁', 'އެންމެ', '▁', 'ފުރަތަމަ', '▁[', 'ޓޫރިޒަމް', ']', '▁', 'ވިޔަފާރިއަށް', '▁', 'އައިރު', '▁', 'ބޭންކުގެ', '▁', 'އިންޓްރެސްޓް', '▁', 'ރޭޓް', '▁', 'އުޅެނީ', '▁21', '-22', '▁', 'ޕަސެންޓުގައި', '.', '▁', 'އެހެންވެ', '▁', 'މި', '▁', 'ހިޔާލުއައީ', '.', '▁', 'މި', '▁', 'އަށް', '▁', 'ކޮމްޕެޓިޝަނެއް', '▁', 'ދީގެން', '▁', 'ނޫނީ', '▁', 'އަޅުގަނޑަށް', '▁', 'އެނގޭ', '▁', 'އިންޓްރެސްޓް', '▁', 'ރޭޓް', '▁', 'ކުޑަ', '▁', 'ނުވާނެކަން', '،', '▁', 'އަފީފު', '▁', 'ވިދާޅުވި', '▁', 'އެވެ', '.']\n",
      "['▁', 'ސީބީއެމް', '▁', 'ހަދާފައިވަނީ', '▁', 'ދުނިޔޭގެ', '▁', 'އެކި', '▁', 'ހިސާބުތަކުގައި', '▁200', '▁', 'އެއްހާ', '▁', 'ބްރާންޗު', '▁', 'ހިންގާ', '،', '▁', 'ސްރީ', '▁', 'ލަންކާގެ', '▁', 'ކޮމާޝަލް', '▁', 'ބޭންކްގެ', '▁55', '▁', 'ޕަސެންޓް', '▁', 'ހިއްސާ', '▁', 'އާއި', '▁', 'ސީބީއެމްގައި', '▁', 'ޓްރީ', '▁', 'ޓޮޕްގެ', '▁45', '▁', 'ޕަސެންޓް', '▁', 'ހިއްސާ', '▁', 'އޮންނަ', '▁', 'ގޮތަށެވެ', '.', '▁', 'މި', '▁', 'ބޭންކް', '▁', 'ހުޅުވާފައިވަނީ', '▁', 'ގާތްގަނޑަކަށް', '▁150', '▁', 'މިލިއަން', '▁', 'ރުފިޔާގެ', '▁', 'ރައުސުލްމާލަކުންނެވެ', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "for text in sentences:\n",
    "    print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have no idea what any of this means, but this looks like it's splitting into words/subwords, and there are no unknown tokens - so it looks promising. Let's initialize a student and teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "xlmr = models.Transformer('xlm-roberta-base')\n",
    "pooler = models.Pooling(\n",
    "    xlmr.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "\n",
    "student = SentenceTransformer(modules=[xlmr, pooler])\n",
    "\n",
    "teacher = SentenceTransformer('paraphrase-distilroberta-base-v2')  # monolingual sentence transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move onto prepping everything for fine-tuning, start with getting the data ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import ParallelSentencesDataset\n",
    "\n",
    "data = ParallelSentencesDataset(student_model=student, teacher_model=teacher, batch_size=32, use_embedding_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_data('../data/entodv-train.tsv.gz', max_sentences=50_000, max_sentence_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(data, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MSELoss(model=student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "\n",
    "student.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='../models/xlmr-dv-sentence-vecs',\n",
    "    optimizer_params={'lr': 2e-5, 'eps': 1e-6, 'correct_bias': False},\n",
    "    save_best_model=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5188bc372fa413aa2565ae5d28228f50ad7b2c4ebb4a82c5900fd598adbb6408"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
